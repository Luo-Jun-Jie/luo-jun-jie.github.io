<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Junjie Luo - Academic Profile</title>
    <link rel="stylesheet" href="./src/styles.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
</head>

<body>

    <header>
        <div class="header-container">
            <h1>Junjie Luo</h1>
            <p>PhD Student, Electrical and Computer Engineering, Purdue University</p>
        </div>
    </header>

    <!-- Navigation with icons -->
    <nav>
        <a href="#about" class="menu-item"><i class="fas fa-user"></i> About Me</a>
        <a href="#education" class="menu-item"><i class="fas fa-flask"></i> Education</a>
        <a href="#publications" class="menu-item"><i class="fas fa-book"></i> Publications</a>
        <a href="#contact" class="menu-item"><i class="fas fa-envelope"></i> Contact</a>
    </nav>

    <!-- Section content -->
    <main>
        <!-- About Me Section -->
        <section id="about" class="section-content block-frame animate-section">
            <h2>About Me</h2>
            <div class="scrollable-content">
                <p>Hello! I am Junjie Luo, a PhD student in Electrical and Computer Engineering at Purdue University. My
                    research focuses on Depth from Defocus methods, particularly Depth from Couple Optical Differentiation
                    (COD), and real-time depth estimation. I am passionate about advancing imaging techniques and developing
                    computational methods to solve complex optical problems.</p>

                <p>My research interests include:</p>
                <ul>
                    <li>Depth from Defocus (DfD) techniques</li>
                    <li>Computational imaging</li>
                    <li>Real-time depth estimation</li>
                    <li>Optical differentiation methods</li>
                </ul>
            </div>
        </section>

        <!-- Education Section -->
        <section id="education" class="section-content block-frame animate-section">
            <h2>Education</h2>
            <div class="scrollable-content">
                <h3>Short CV</h3>
                <ul>
                    <li>PhD Student, Electrical and Computer Engineering, Purdue University (Present)</li>
                    <li>MSc in Computer Information and Technology, Purdue University</li>
                    <li>BSc in Computer Science, Sun Yat-sun University</li>
                </ul>
            </div>
        </section>

        <!-- Publications Section -->
        <section id="publications" class="section-content block-frame animate-section">
            <h2>Publications</h2>
            <div class="scrollable-content publications-container">
                <div class="publication-card">
                    <div class="publication-info">
                        <h3>Focal Split: Untethered Snapshot Depth from Differential Defocus</h3>
                        <p><strong>Authors:</strong> Luo, J., Mamish, J., Fu, A., Concannon, T., Hester, J., Alexander, E., Guo, Q.</p>
                        <p class="publication-abstract"><strong>Abstract:</strong>
                            <br>We present Focal Split, a snapshot depth from differential defocus method that uses two images captured with different sensor distances by a beamsplitter...
                        </p>
                        <p><strong>Link:</strong> <a href="" target="_blank">[arXiv]</a> | <strong>Project Page:</strong> <a href="projects/FocalSplit/FocalSplit.html" target="_blank">[page]</a></p>
                    </div>
                    <div class="publication-meta">
                        <p><strong>Preprinted:</strong> 2025, IEEE / CVF Computer Vision and Pattern Recognition Conference (CVPR)</p>
                    </div>
                </div>
                <div class="publication-card">
                    <div class="publication-info">
                        <h3>Blurry-Edges: Photon-Limited Depth Estimation from Defocused Boundaries</h3>
                        <p><strong>Authors:</strong> Xu, W., Wagner, C., Luo, J., Guo, Qi.</p>
                        <p class="publication-abstract"><strong>Abstract:</strong>
                            <br>We present a novel approach to robustly measure object depths from photon-limited images along the defocused boundaries...
                        </p>
                        <p><strong>Link:</strong> <a href="" target="_blank">[arXiv]</a></p>
                    </div>
                    <div class="publication-meta">
                        <p><strong>Preprinted:</strong> 2025, IEEE / CVF Computer Vision and Pattern Recognition Conference (CVPR)</p>
                    </div>
                </div>
                <div class="publication-card">
                    <div class="publication-info">
                        <h3>Depth from Coupled Optical Differentiation</h3>
                        <p><strong>Authors:</strong> Luo, J., Liu, Y., Alexander, E. and Guo, Q.</p>
                        <p class="publication-abstract"><strong>Abstract:</strong>
                            <br>We propose depth from coupled optical differentiation, a low-computation
                            passive-lighting 3D sensing mechanism...
                        </p>
                        <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2409.10725" target="_blank">[arXiv]</a></p>
                    </div>
                    <div class="publication-meta">
                        <p><strong>Preprinted:</strong> 2024, arXiv preprint arXiv:2409.10725</p>
                    </div>
                </div>
                <div class="publication-card">
                    <div class="publication-info">
                        <h3>CT-Bound: Fast Boundary Estimation From Noisy Images</h3>
                        <p><strong>Authors:</strong> Xu, W., Luo, J. and Guo, Q.</p>
                        <p class="publication-abstract"><strong>Abstract:</strong>
                            <br>We present CT-Bound, a robust and fast boundary detection method for very noisy images...
                        </p>
                        <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.16494" target="_blank">[arXiv]</a></p>
                    </div>
                    <div class="publication-meta">
                        <p><strong>Published:</strong> 2024, IEEE 26th International Workshop on Multimedia Signal Processing (MMSP) (pp. 1-6)</p>
                    </div>
                </div>
                <div class="publication-card">
                    <div class="publication-info">
                        <h3>Generative Quanta Color Imaging</h3>
                        <p><strong>Authors:</strong> Purohit, V., Luo, J., Chi, Y., Guo, Q., Chan, S.H. and Qiu, Q.</p>
                        <p class="publication-abstract"><strong>Abstract:</strong>
                            <br>The astonishing development of single-photon cameras has created an unprecedented
                            opportunity...
                        </p>
                        <p><strong>Link:</strong> <a href="https://arxiv.org/abs/2403.19066" target="_blank">[arXiv]</a></p>
                    </div>
                    <div class="publication-meta">
                        <p><strong>Published:</strong> 2024, IEEE/CVF Conference on Computer Vision and Pattern
                            Recognition</p>
                    </div>
                </div>
                <!-- Extra space at the bottom for better scrolling -->
                <div style="height: 50px;"></div>
            </div>
        </section>

        <!-- Contact Section -->
        <section id="contact" class="section-content block-frame animate-section">
            <h2>Contact</h2>
            <div class="scrollable-content">
                <p>You can reach me at:</p>
                <ul>
                    <li>Email: luo330@purdue.edu</li>
                    <li>Office: Flex Lab 3095, 205 Gates Rd, West Lafayette, IN 47906</li>
                </ul>
            </div>
        </section>
    </main>

    <footer>
        <div class="footer-content">
            <div class="social-icons">
                <a href="https://www.linkedin.com/in/junjiel/" target="_blank"><i class="fab fa-linkedin"></i></a>
                <a href="https://github.com/guo-research-group" target="_blank"><i class="fab fa-github"></i></a>
                <a href="mailto:luo330@purdue.edu"><i class="fas fa-envelope"></i></a>
            </div>
            <img src="./img/Purdue_logo.png" alt="Purdue University Logo" class="purdue-logo">
        </div>
        <div class="footer-bottom">
            <p>&copy; 2025 Junjie Luo | Last updated: Feb. 2025</p>
        </div>
    </footer>

    <script src="./src/scripts.js"></script>

</body>

</html>
